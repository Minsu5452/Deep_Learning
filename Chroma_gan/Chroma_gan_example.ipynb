{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"5uLxCiO0zs-v"},"source":["# ChromaGAN"],"id":"5uLxCiO0zs-v"},{"cell_type":"markdown","metadata":{"id":"_MDiFUZkzs-y"},"source":["## 1. Setup\n","Mount Google Drive (if using Colab) and set up the environment."],"id":"_MDiFUZkzs-y"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGEDIEMdzs-z"},"outputs":[],"source":["from google.colab import drivedrive.mount('/content/drive')import osos.chdir('/content/drive/MyDrive/ChromaGAN')  # Adjust to your directory"],"id":"OGEDIEMdzs-z"},{"cell_type":"markdown","metadata":{"id":"bLzssWKIzs-1"},"source":["## 2. Data Preparation\n","Load the dataset, perform preprocessing, and prepare for training."],"id":"bLzssWKIzs-1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Afmq2QGxzs-2"},"outputs":[],"source":["# Example: Load and preprocess datasetfrom torchvision import transforms, datasetstransform = transforms.Compose([    transforms.Resize((224, 224)),    transforms.ToTensor()])train_dataset = datasets.ImageFolder(root='./train', transform=transform)train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)"],"id":"Afmq2QGxzs-2"},{"cell_type":"markdown","metadata":{"id":"ihVNDGwIzs-3"},"source":["## 3. Model Implementation\n","Define the ChromaGAN model using PyTorch."],"id":"ihVNDGwIzs-3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"keJ_Miq_zs-3"},"outputs":[],"source":["import torch.nn as nnclass ChromaGAN(nn.Module):    def __init__(self):        super(ChromaGAN, self).__init__()        # Define layers here        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)        # Add more layers as per architecture    def forward(self, x):        x = self.conv1(x)        # Add forward pass logic        return xmodel = ChromaGAN()"],"id":"keJ_Miq_zs-3"},{"cell_type":"markdown","metadata":{"id":"yOjGkNh3zs-4"},"source":["## 4. Training\n","Train the model and log training losses."],"id":"yOjGkNh3zs-4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cmEJHTh7zs-5"},"outputs":[],"source":["# Training Loopimport torch.optim as optimcriterion = nn.MSELoss()optimizer = optim.Adam(model.parameters(), lr=1e-3)for epoch in range(10):    for inputs, targets in train_loader:        # Forward pass        outputs = model(inputs)        loss = criterion(outputs, targets)        # Backward pass        optimizer.zero_grad()        loss.backward()        optimizer.step()    print(f'Epoch {epoch}, Loss: {loss.item()}')"],"id":"cmEJHTh7zs-5"},{"cell_type":"markdown","metadata":{"id":"YIqWhfAWzs-6"},"source":["## 5. Results\n","Visualize the colorized images and compare against ground truth."],"id":"YIqWhfAWzs-6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1VO1f8uvzs-6"},"outputs":[],"source":["# Visualizationimport matplotlib.pyplot as pltinputs, _ = next(iter(train_loader))outputs = model(inputs)plt.figure(figsize=(10, 5))for i in range(5):    plt.subplot(2, 5, i+1)    plt.imshow(inputs[i][0].cpu(), cmap='gray')    plt.subplot(2, 5, i+6)    plt.imshow(outputs[i].detach().cpu().permute(1, 2, 0))plt.show()"],"id":"1VO1f8uvzs-6"}]}